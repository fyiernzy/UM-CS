# Question 1
## 1.a)
```pseudo
FUNCTION FIND-PRODUCT(A, L, H)
	IF L == H THEN
		RETURN A[L]
	ENDIF
	IF H - L == 1 THEN
		RETURN A[L] * A[H]
	ENDIF
	M = L + (H - L) / 2
	RETURN A[M] * FIND-PRODUCT(A, L, M - 1) 
				* FIND-PRODUCT(A, M + 1, H)
END FUNCTION
```
```python
def find_product(A, L, H):
    if L == H:
        return A[L]
    if L == H - 1:
        return A[L] * A[H]
    M = L + (H - L) // 2
    return A[mid] * find_product(A, L, M - 1) 
				  * find_product(A, M + 1, H)
```

## 1.b)
![[Pasted image 20240618161350.png]]

## 1.c)
![[Pasted image 20240618163834.png]]

# Question 2
## 2.a)
Average search time = $O(1)$

## 2.b)
A [[Hash Collision]] is a condition where two or more keys have the same hash value. To illustrate, the hash $h(k_1)$ of a key $k_1$ is identical to hash $h(k_2)$ of key $k_2$, but $k_{1} \neq k_{2}$.

## 2.c)
The load factor $\alpha$ is the average number of elements stored in the hash table. It is defined as the ratio of the number of elements stored in the hash table to the number of the slots available in the table. Given $\alpha = \left( \frac{n_{occupied}}{n_{total}}\right)$ , with the assumption of simple uniform hashing, the expected length of a hash table is $n_{occupied} = \alpha \cdot n_{total}$ and $\alpha$ for each slot.

## 2.d)
The formula of double hashing is given as follow:
$$H(k,i)=(H_{1}(k)+i\cdot H_{2}(k))\ \%\ m$$
where $H_{1}(k)$ and $H_{2}(k)$ are auxiliary hash functions, and $i$ is used for probing.

| Key | $H_{1}(k)\ (k\ \%\ m)$ | $H_{2}(k)\ (7-(k\ \%\ 7))$ |                           $H(k, i)$                            |
| :-: | :--------------------: | :------------------------: | :------------------------------------------------------------: |
| 24  |    $24\ \%\ 10 = 4$    |                            |                               4                                |
| 46  |    $46\ \%\ 10 = 6$    |                            |                               6                                |
| 83  |    $83\ \%\ 10 = 3$    |                            |                               3                                |
| 13  |    $13\ \%\ 3 = 3$     |    $7-(13\ \%\ 7) = 1$     | $(3 + 1 \cdot 1)\ \%\ 10=4$<br>$(3 + 2 \cdot 1)\ \%\ 10=5$<br> |
| 14  |    $14\ \%\ 10 = 4$    |    $7-(14\ \%\ 7) = 7$     |                  $(4 + 1 \cdot 7)\ \%\ 10=1$                   |
| 53  |    $53\ \%\ 10 = 3$    |    $7-(53\ \%\ 7) = 3$     |   $(3 + 1 \cdot 3)\ \%\ 10=6$<br>$(3 + 2 \cdot 3)\ \%\ 10=9$   |
| 70  |    $70\ \%\ 10 = 0$    |                            |                               0                                |
Given $m=10$.

| Hash | Key |
| :--: | :-: |
|  0   | 70  |
|  1   | 14  |
|  2   | NIL |
|  3   | 83  |
|  4   | 24  |
|  5   | 13  |
|  6   | 46  |
|  7   | NIL |
|  8   | NIL |
|  9   | 53  |

# Question 3
## 3.a)
- If **Randomized Quick Select** is used, $\text{log}_{2}\ n$ times comparisons are needed.
- If **Linear Searching** is used, at least $n-1$ times comparisons are necessary.

## 3.b)
To find the $i$-th largest number in a set of  $n$ numbers using a comparison-based algorithm, two approaches can be used:

1. **Randomized Quick Select** uses the `PARTITION` method to divide the array such that numbers smaller than the pivot are on the left and numbers larger than the pivot are on the right. It partially sorts the array, and returns as soon as it finds the $i$-th largest number. Its expected running time is $O(n)$, but the worst-case running time is $O(n^2)$.
2. **Randomized Quick Sort** also uses `PARTITION` to divide the array and sorts all elements in non-decreasing order.  return the element at $i$-th place. After sorting, the element at the $i$-th place is returned. Its worst-case running time is $O(n^2)$, while average running time is $O(n\ log\ n)$

## 3.c)
$O(1)$. Given the array is sorted, we can directly access the number at $7^{th}$ index (0-based index). However, in an unsorted array, we can use **Randomized Quick Select** which has worst case running time of $O(n^2)$. To optimize the solution, we can use Median of Medians algorithm, which has  the best asymptotic worst-case running time of $O(n)$.

```python
def median_of_medians(A, i):
    #divide A into sublists of len 5
    sublists = [A[j:j+5] for j in range(0, len(A), 5)] # O(n)
    medians = [sorted(sublist)[len(sublist)/2] for sublist in sublists] # O(n) if len(sublist) = 5
    if len(medians) <= 5:
        pivot = sorted(medians)[len(medians)/2]  
    else:
        #the pivot is the median of the medians
        pivot = median_of_medians(medians, len(medians)/2)

    #partitioning step
    low = [j for j in A if j <= pivot] # O(n)
    high = [j for j in A if j > pivot] # O(n)

    k = len(low)
    if i < k:
        return median_of_medians(low,i)
    elif i > k:
        return median_of_medians(high,i-k-1) # -1 to exclude median
    else: #pivot = k
        return pivot
```

# Question 4
## 4.a)
The [[Greedy Algorithm]] is a technique that finds the locally optimal solution in the subproblems of a problem with the hope of finding the globally optimal solution for the problem.

## 4.b)
The parameter used to determine the job sequence is `deadline`. This is because we want to minimize the lateness, which is calculated as $\text{Actual Finish Date}-\text{Deadline}$. For each iteration, we choose the project with nearest deadline and repeat the process.


**Iteration 1**:
```bash
      |  t1  t2  t3  t4  t5  t6  t7
------|-----------------------------
Job 4 | [X] [ ] [ ] [ ] [ ] [ ] [ ]
```

**Iteration 2**:
```bash
      |  t1  t2  t3  t4  t5  t6  t7
------|-----------------------------
Job 4 | [X] [ ] [ ] [ ] [ ] [ ] [ ]
Job 3 | [ ] [X] [X] [X] [ ] [ ] [ ] 
```

**Iteration 3**:
```bash
      |  t1  t2  t3  t4  t5  t6  t7
------|-----------------------------
Job 4 | [X] [ ] [ ] [ ] [ ] [ ] [ ]
Job 3 | [ ] [X] [X] [X] [ ] [ ] [ ] 
Job 1 | [ ] [ ] [ ] [ ] [X] [|] [ ] 
```

The question shows that `Job 1` uses about 1.5 unit time. Since the question does not clearly state that fractional times are not allowed, and it's logically to finish a job within half a day and continue with another job, we assume that fractional times are permitted. `|` (pipeline) indicates 0.5.

**Iteration 4**:
```bash
      |  t1  t2  t3  t4  t5  t6  t7  t8  t9  t10
------|-----------------------------------------
Job 4 | [X] [ ] [ ] [ ] [ ] [ ] [ ] [ ] [ ]  [ ] 
Job 3 | [ ] [X] [X] [X] [ ] [ ] [ ] [ ] [ ]  [ ] 
Job 1 | [ ] [ ] [ ] [ ] [X] [|] [ ] [ ] [ ]  [ ] 
Job 2 | [ ] [ ] [ ] [ ] [ ] [|] [X] [X] [X]  [|] 
```

**Total lateness of time**

| Job | Start | End | Deadline | Lateness |
| --- | ----- | --- | -------- | -------- |
| 4   | 1     | 1   | 1        | 0        |
| 3   | 2     | 4   | 3        | 1        |
| 1   | 5     | 6.5 | 5        | 1.5      |
| 2   | 6.5   | 9.5 | 7        | 2.5      |

Assuming the total lateness time is the sum of the lateness caused in each project, it is calculated as follow:
$$\text{Total Lateness}=0+1+1.5+2.5=5$$

The best job sequence, determined using Greedy Algorithm with parameter set to `deadline`, is `4 > 3 > 1 > 2`, with total lateness of 5.

# Reference
---
1. _Median-finding Algorithm | Brilliant Math & Science Wiki_. (n.d.). https://brilliant.org/wiki/median-finding-algorithm/
2. Theory Group. (2020, February 10). _Illustration of Linear Time Median of Medians Algorithm_ [Video]. YouTube. https://www.youtube.com/watch?v=_xp5FdAvIK8
3. Basics Strong. (2020, July 17). _Median of medians Algorithm - [Linear Time Complexity O(n)]  #PART-1_ [Video]. YouTube. https://www.youtube.com/watch?v=sNtu2oGDRvU